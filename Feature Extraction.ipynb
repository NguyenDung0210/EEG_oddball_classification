{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9d37e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tìm thấy 42 file EEG\n",
      "DONE → optimized_eeg_features.csv shape: (30396, 1782)\n"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from scipy import signal\n",
    "from scipy.stats import entropy\n",
    "import pywt\n",
    "from joblib import Parallel, delayed\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# =================== HÀM TÍNH FEATURE ===================\n",
    "\n",
    "def compute_band_power(data, sfreq):\n",
    "    freqs, psd = signal.welch(data, sfreq, nperseg=min(256, data.shape[-1]))\n",
    "    bands = {'delta': (0.5,4), 'theta': (4,8), 'alpha': (8,13),\n",
    "             'beta': (13,30), 'gamma': (30,45)}\n",
    "    power_features = {}\n",
    "    for band, (low, high) in bands.items():\n",
    "        idx = np.logical_and(freqs >= low, freqs <= high)\n",
    "        power_features[band] = np.trapz(psd[:, idx], freqs[idx], axis=1)\n",
    "    return power_features\n",
    "\n",
    "def compute_spectral_entropy(data, sfreq):\n",
    "    freqs, psd = signal.welch(data, sfreq, nperseg=min(256, data.shape[-1]))\n",
    "    psd_norm = psd / np.sum(psd, axis=1, keepdims=True)\n",
    "    return -np.sum(psd_norm * np.log2(psd_norm + 1e-10), axis=1)\n",
    "\n",
    "def compute_wavelet_features(data, wavelet='db4', level=3):\n",
    "    n_channels = data.shape[0]\n",
    "    features = {'coeffs_mean': [], 'coeffs_energy': []}\n",
    "    for ch in range(n_channels):\n",
    "        coeffs = pywt.wavedec(data[ch], wavelet, level=level)\n",
    "        features['coeffs_mean'].append([np.mean(np.abs(c)) for c in coeffs])\n",
    "        features['coeffs_energy'].append([np.sum(c**2) for c in coeffs])\n",
    "    for k in features:\n",
    "        features[k] = np.array(features[k])\n",
    "    return features\n",
    "\n",
    "def combine_features(bp, spec_ent, wave_feats, ch_names):\n",
    "    all_feats = []\n",
    "    for i, ch in enumerate(ch_names):\n",
    "        ch_feats = []\n",
    "        for band in bp:\n",
    "            ch_feats.append(bp[band][i])\n",
    "        ch_feats.append(spec_ent[i])\n",
    "        for lvl in range(wave_feats['coeffs_mean'].shape[1]):\n",
    "            ch_feats.append(wave_feats['coeffs_mean'][i][lvl])\n",
    "            ch_feats.append(wave_feats['coeffs_energy'][i][lvl])\n",
    "        all_feats.extend(ch_feats)\n",
    "    return all_feats\n",
    "\n",
    "# =================== XỬ LÝ 1 SUBJECT ===================\n",
    "\n",
    "def process_subject(preproc_file):\n",
    "    subject = preproc_file.parent.parent.name \n",
    "    \n",
    "    # --- Tìm file events của subject ---\n",
    "    events_file = Path(f\"data/EEG/eeg/tsv/{subject}_task-oddball_events.tsv\")\n",
    "    \n",
    "    if not events_file.exists():\n",
    "        print(f\"Không tìm thấy events cho {subject}\")\n",
    "        return []\n",
    "\n",
    "    # ---- Load events ----\n",
    "    events_tsv = pd.read_csv(events_file, sep=\"\\t\")\n",
    "    try:\n",
    "        raw = mne.io.read_raw_fif(preproc_file, preload=True, verbose=False)\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi đọc {preproc_file}: {e}\")\n",
    "        return []\n",
    "    sfreq = raw.info['sfreq']\n",
    "    ch_names = raw.ch_names\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for idx, row in events_tsv.iterrows():\n",
    "        onset_sample = int(row[\"onset\"])\n",
    "        label = row[\"event_type\"] \n",
    "\n",
    "        segment_samples = int(1.0 * sfreq)\n",
    "        data = raw.get_data(start=onset_sample, stop=onset_sample + segment_samples)\n",
    "\n",
    "\n",
    "        bp = compute_band_power(data, sfreq)\n",
    "        spec_ent = compute_spectral_entropy(data, sfreq)\n",
    "        wave_feats = compute_wavelet_features(data)\n",
    "        feats = combine_features(bp, spec_ent, wave_feats, ch_names)\n",
    "\n",
    "        results.append([subject, preproc_file.name, idx, label] + feats)\n",
    "\n",
    "    return results\n",
    "\n",
    "# =================== BATCH PROCESS ===================\n",
    "\n",
    "def extract_features_batch(derivatives_path, output_file='eeg_features.csv', n_jobs=-1):\n",
    "    derivatives_path = Path(derivatives_path)\n",
    "    files = list(derivatives_path.rglob('*_desc-preproc_eeg.fif'))\n",
    "    print(f\"Tìm thấy {len(files)} file EEG\")\n",
    "\n",
    "    # Song song hóa\n",
    "    all_results = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(process_subject)(f) for f in files\n",
    "    )\n",
    "\n",
    "    flat = [item for sublist in all_results for item in sublist]\n",
    "\n",
    "    df = pd.DataFrame(flat)\n",
    "    df = df.rename(columns={0: \"subject\", 1: \"file\", 2: \"trial\", 3: \"label\"})\n",
    "    feature_cols = [f\"f{i}\" for i in range(df.shape[1] - 4)]\n",
    "    df.columns = [\"subject\", \"file\", \"trial\", \"label\"] + feature_cols\n",
    "\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(\"DONE →\", output_file, \"shape:\", df.shape)\n",
    "\n",
    "    return df\n",
    "\n",
    "# =================== RUN ===================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    extract_features_batch(\n",
    "        \"data/EEG/derivatives/preprocessing\",\n",
    "        output_file=\"optimized_eeg_features.csv\",\n",
    "        n_jobs=-1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95d64140",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "tsv = pd.read_csv(\"eeg_features.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9eb70bc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>file</th>\n",
       "      <th>trial</th>\n",
       "      <th>label</th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>...</th>\n",
       "      <th>f1768</th>\n",
       "      <th>f1769</th>\n",
       "      <th>f1770</th>\n",
       "      <th>f1771</th>\n",
       "      <th>f1772</th>\n",
       "      <th>f1773</th>\n",
       "      <th>f1774</th>\n",
       "      <th>f1775</th>\n",
       "      <th>f1776</th>\n",
       "      <th>f1777</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sub-01</td>\n",
       "      <td>sub-01_task-oddball_desc-preproc_eeg.fif</td>\n",
       "      <td>0</td>\n",
       "      <td>S  5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.810764e-11</td>\n",
       "      <td>5.100409e-12</td>\n",
       "      <td>1.207314</td>\n",
       "      <td>...</td>\n",
       "      <td>2.839575e-12</td>\n",
       "      <td>1.260830</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>2.561104e-06</td>\n",
       "      <td>9.135965e-07</td>\n",
       "      <td>1.814907e-10</td>\n",
       "      <td>6.672152e-08</td>\n",
       "      <td>4.236073e-12</td>\n",
       "      <td>2.901080e-09</td>\n",
       "      <td>1.476699e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sub-01</td>\n",
       "      <td>sub-01_task-oddball_desc-preproc_eeg.fif</td>\n",
       "      <td>1</td>\n",
       "      <td>S  5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.188307e-11</td>\n",
       "      <td>5.867867e-12</td>\n",
       "      <td>1.148442</td>\n",
       "      <td>...</td>\n",
       "      <td>4.879814e-12</td>\n",
       "      <td>1.186929</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>1.774518e-06</td>\n",
       "      <td>1.054273e-06</td>\n",
       "      <td>2.410315e-10</td>\n",
       "      <td>7.116892e-08</td>\n",
       "      <td>2.195702e-12</td>\n",
       "      <td>3.421914e-09</td>\n",
       "      <td>1.024458e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sub-01</td>\n",
       "      <td>sub-01_task-oddball_desc-preproc_eeg.fif</td>\n",
       "      <td>2</td>\n",
       "      <td>S  5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.324512e-11</td>\n",
       "      <td>8.520660e-12</td>\n",
       "      <td>3.392780</td>\n",
       "      <td>...</td>\n",
       "      <td>3.554239e-12</td>\n",
       "      <td>3.292150</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>2.908802e-08</td>\n",
       "      <td>1.034735e-06</td>\n",
       "      <td>2.683197e-10</td>\n",
       "      <td>8.124062e-08</td>\n",
       "      <td>8.471733e-12</td>\n",
       "      <td>3.411116e-09</td>\n",
       "      <td>2.550000e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sub-01</td>\n",
       "      <td>sub-01_task-oddball_desc-preproc_eeg.fif</td>\n",
       "      <td>3</td>\n",
       "      <td>S  5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.258177e-11</td>\n",
       "      <td>8.381647e-12</td>\n",
       "      <td>1.492794</td>\n",
       "      <td>...</td>\n",
       "      <td>3.724248e-12</td>\n",
       "      <td>1.537859</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>1.368634e-06</td>\n",
       "      <td>9.047409e-07</td>\n",
       "      <td>1.643513e-10</td>\n",
       "      <td>7.403810e-08</td>\n",
       "      <td>8.404831e-12</td>\n",
       "      <td>3.283984e-09</td>\n",
       "      <td>3.630522e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sub-01</td>\n",
       "      <td>sub-01_task-oddball_desc-preproc_eeg.fif</td>\n",
       "      <td>4</td>\n",
       "      <td>S  7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.355817e-11</td>\n",
       "      <td>7.498204e-12</td>\n",
       "      <td>1.444070</td>\n",
       "      <td>...</td>\n",
       "      <td>2.766799e-12</td>\n",
       "      <td>1.493626</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>4.057098e-06</td>\n",
       "      <td>7.838209e-07</td>\n",
       "      <td>1.218728e-10</td>\n",
       "      <td>5.154912e-08</td>\n",
       "      <td>1.252141e-12</td>\n",
       "      <td>2.464448e-09</td>\n",
       "      <td>6.117372e-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1782 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject                                      file  trial label   f0   f1  \\\n",
       "0  sub-01  sub-01_task-oddball_desc-preproc_eeg.fif      0  S  5  0.0  0.0   \n",
       "1  sub-01  sub-01_task-oddball_desc-preproc_eeg.fif      1  S  5  0.0  0.0   \n",
       "2  sub-01  sub-01_task-oddball_desc-preproc_eeg.fif      2  S  5  0.0  0.0   \n",
       "3  sub-01  sub-01_task-oddball_desc-preproc_eeg.fif      3  S  5  0.0  0.0   \n",
       "4  sub-01  sub-01_task-oddball_desc-preproc_eeg.fif      4  S  7  0.0  0.0   \n",
       "\n",
       "    f2            f3            f4        f5  ...         f1768     f1769  \\\n",
       "0  0.0  2.810764e-11  5.100409e-12  1.207314  ...  2.839575e-12  1.260830   \n",
       "1  0.0  1.188307e-11  5.867867e-12  1.148442  ...  4.879814e-12  1.186929   \n",
       "2  0.0  1.324512e-11  8.520660e-12  3.392780  ...  3.554239e-12  3.292150   \n",
       "3  0.0  1.258177e-11  8.381647e-12  1.492794  ...  3.724248e-12  1.537859   \n",
       "4  0.0  3.355817e-11  7.498204e-12  1.444070  ...  2.766799e-12  1.493626   \n",
       "\n",
       "      f1770         f1771         f1772         f1773         f1774  \\\n",
       "0  0.000101  2.561104e-06  9.135965e-07  1.814907e-10  6.672152e-08   \n",
       "1  0.000072  1.774518e-06  1.054273e-06  2.410315e-10  7.116892e-08   \n",
       "2  0.000012  2.908802e-08  1.034735e-06  2.683197e-10  8.124062e-08   \n",
       "3  0.000059  1.368634e-06  9.047409e-07  1.643513e-10  7.403810e-08   \n",
       "4  0.000133  4.057098e-06  7.838209e-07  1.218728e-10  5.154912e-08   \n",
       "\n",
       "          f1775         f1776         f1777  \n",
       "0  4.236073e-12  2.901080e-09  1.476699e-14  \n",
       "1  2.195702e-12  3.421914e-09  1.024458e-14  \n",
       "2  8.471733e-12  3.411116e-09  2.550000e-14  \n",
       "3  8.404831e-12  3.283984e-09  3.630522e-14  \n",
       "4  1.252141e-12  2.464448e-09  6.117372e-15  \n",
       "\n",
       "[5 rows x 1782 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "183472df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1308857"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "tsv = pd.read_csv(\"data/EEG/sub-01/eeg/sub-01_task-oddball_events.tsv\", sep=\"\\t\")\n",
    "tsv[\"onset\"].max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9ffc419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file data/EEG/derivatives/preprocessing/sub-01/eeg/sub-01_task-oddball_desc-preproc_eeg.fif...\n",
      "    Range : 0 ... 1371319 =      0.000 ...  1371.319 secs\n",
      "Ready.\n",
      "Reading 0 ... 1371319  =      0.000 ...  1371.319 secs...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1371320"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = mne.io.read_raw_fif(\"data/EEG/derivatives/preprocessing/sub-01/eeg/sub-01_task-oddball_desc-preproc_eeg.fif\", preload=True)\n",
    "raw.n_times\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29782db8",
   "metadata": {},
   "source": [
    "V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93e22c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tìm thấy 42 file EEG\n",
      "DONE → optimized_oddball_features.csv shape: (30396, 116)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Đoạn mã này thực hiện trích xuất đặc trưng EEG tập trung vào các kênh ROI liên quan đến phản ứng Oddball/P300 (như Fz, Cz, Pz,…).\n",
    "Với mỗi sự kiện, tín hiệu EEG được cắt trong cửa sổ từ –200 ms đến 800 ms, \n",
    "chuẩn hóa baseline rồi tính toán các nhóm đặc trưng chính gồm năng lượng dải tần (band power), \n",
    "entropy phổ và đặc trưng wavelet đa mức. Các đặc trưng theo từng kênh được ghép lại thành một vector duy nhất, \n",
    "tạo thành bộ feature tối ưu phục vụ cho phân tích và mô hình học máy trong các nghiên cứu Oddball/P300.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from scipy import signal\n",
    "import pywt\n",
    "from joblib import Parallel, delayed\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# =================== CẤU HÌNH KÊNH QUAN TRỌNG (ODDBALL ROI) ===================\n",
    "# Danh sách các kênh tiêu chuẩn phản ánh tốt nhất P300/Oddball\n",
    "# Bạn cần kiểm tra xem tên kênh trong file raw của bạn có khớp format này không (ví dụ 'Cz' hay 'EEG001')\n",
    "ROI_CHANNELS = ['Fz', 'Cz', 'Pz', 'Oz', 'P3', 'P4', 'C3', 'C4'] \n",
    "\n",
    "# =================== HÀM TÍNH FEATURE (GIỮ NGUYÊN) ===================\n",
    "def compute_band_power(data, sfreq):\n",
    "    # Giảm nperseg nếu đoạn dữ liệu ngắn hơn 1s\n",
    "    n_samples = data.shape[-1]\n",
    "    freqs, psd = signal.welch(data, sfreq, nperseg=min(128, n_samples)) \n",
    "    bands = {'delta': (0.5,4), 'theta': (4,8), 'alpha': (8,13),\n",
    "             'beta': (13,30), 'gamma': (30,45)}\n",
    "    power_features = {}\n",
    "    for band, (low, high) in bands.items():\n",
    "        idx = np.logical_and(freqs >= low, freqs <= high)\n",
    "        if np.sum(idx) == 0: # Tránh lỗi nếu không có tần số nào lọt vào band\n",
    "            power_features[band] = np.zeros(data.shape[0])\n",
    "        else:\n",
    "            power_features[band] = np.trapz(psd[:, idx], freqs[idx], axis=1)\n",
    "    return power_features\n",
    "\n",
    "def compute_spectral_entropy(data, sfreq):\n",
    "    n_samples = data.shape[-1]\n",
    "    freqs, psd = signal.welch(data, sfreq, nperseg=min(128, n_samples))\n",
    "    psd_norm = psd / np.sum(psd, axis=1, keepdims=True)\n",
    "    return -np.sum(psd_norm * np.log2(psd_norm + 1e-10), axis=1)\n",
    "\n",
    "def compute_wavelet_features(data, wavelet='db4', level=3):\n",
    "    n_channels = data.shape[0]\n",
    "    features = {'coeffs_mean': [], 'coeffs_energy': []}\n",
    "    for ch in range(n_channels):\n",
    "        # Mode 'periodic' hoặc 'symmetric' thường tốt cho tín hiệu ngắn\n",
    "        coeffs = pywt.wavedec(data[ch], wavelet, level=level, mode='symmetric')\n",
    "        features['coeffs_mean'].append([np.mean(np.abs(c)) for c in coeffs])\n",
    "        features['coeffs_energy'].append([np.sum(c**2) for c in coeffs])\n",
    "    for k in features:\n",
    "        features[k] = np.array(features[k])\n",
    "    return features\n",
    "\n",
    "def combine_features(bp, spec_ent, wave_feats, ch_names):\n",
    "    all_feats = []\n",
    "    for i, ch in enumerate(ch_names):\n",
    "        ch_feats = []\n",
    "        for band in bp:\n",
    "            ch_feats.append(bp[band][i])\n",
    "        ch_feats.append(spec_ent[i])\n",
    "        for lvl in range(wave_feats['coeffs_mean'].shape[1]):\n",
    "            ch_feats.append(wave_feats['coeffs_mean'][i][lvl])\n",
    "            ch_feats.append(wave_feats['coeffs_energy'][i][lvl])\n",
    "        all_feats.extend(ch_feats)\n",
    "    return all_feats\n",
    "\n",
    "# =================== XỬ LÝ 1 SUBJECT ===================\n",
    "\n",
    "def process_subject(preproc_file):\n",
    "    subject = preproc_file.parent.parent.name \n",
    "    \n",
    "    # --- Tìm file events ---\n",
    "    events_file = Path(f\"data/EEG/eeg/tsv/{subject}_task-oddball_events.tsv\")\n",
    "    if not events_file.exists():\n",
    "        return []\n",
    "\n",
    "    events_tsv = pd.read_csv(events_file, sep=\"\\t\")\n",
    "    try:\n",
    "        raw = mne.io.read_raw_fif(preproc_file, preload=True, verbose=False)\n",
    "        raw.set_annotations(None)\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi đọc file {preproc_file}: {e}\")\n",
    "        return []\n",
    "        \n",
    "    sfreq = raw.info['sfreq']\n",
    "    \n",
    "    # --- [NEW] CHỌN KÊNH (CHANNEL SELECTION) ---\n",
    "    # Lọc lấy các kênh có trong danh sách ROI và tồn tại trong dữ liệu\n",
    "    available_channels = [ch for ch in ROI_CHANNELS if ch in raw.ch_names]\n",
    "    if len(available_channels) == 0:\n",
    "        # Fallback: Nếu tên kênh không khớp chuẩn 10-20, lấy tạm 10 kênh đầu hoặc báo lỗi\n",
    "        print(f\"Warning: Không tìm thấy kênh ROI chuẩn cho {subject}. Dùng tất cả kênh.\")\n",
    "        available_channels = raw.ch_names\n",
    "    \n",
    "    # Chỉ lấy dữ liệu của các kênh đã chọn để xử lý\n",
    "    # Lưu ý: Ta không drop kênh trong 'raw' để tránh lỗi bộ nhớ, ta sẽ dùng tham số 'picks' khi get_data\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    # --- [NEW] THIẾT LẬP CỬA SỔ THỜI GIAN ---\n",
    "    tmin, tmax = -0.2, 0.8\n",
    "    \n",
    "    for idx, row in events_tsv.iterrows():\n",
    "        # Lưu ý: 'onset' trong BIDS tsv thường là GIÂY. Cần nhân với sfreq nếu nó là float.\n",
    "        # Nếu file tsv của bạn onset là index mẫu (int), hãy giữ nguyên logic cũ.\n",
    "        # Dưới đây giả định row[\"onset\"] là index mẫu (như code gốc của bạn):\n",
    "        center_sample = int(row[\"onset\"]) \n",
    "        \n",
    "        # Tính index bắt đầu và kết thúc\n",
    "        start_sample = center_sample + int(tmin * sfreq)\n",
    "        stop_sample = center_sample + int(tmax * sfreq)\n",
    "\n",
    "        # Kiểm tra biên (tránh lấy chỉ số âm hoặc vượt quá độ dài)\n",
    "        if start_sample < 0 or stop_sample > raw.n_times:\n",
    "            continue\n",
    "\n",
    "        # --- [NEW] CẮT DỮ LIỆU VỚI PICKS ---\n",
    "        # picks=available_channels: Chỉ lấy dữ liệu các kênh quan trọng\n",
    "        data = raw.get_data(picks=available_channels, start=start_sample, stop=stop_sample)\n",
    "        \n",
    "        # Optional: BASELINE CORRECTION (Trừ đi trung bình của đoạn -0.2 đến 0)\n",
    "        # Đoạn baseline là từ đầu (index 0) đến mốc 0s (tương ứng 0.2s đầu tiên)\n",
    "        baseline_samples = int(0.2 * sfreq)\n",
    "        baseline_mean = np.mean(data[:, :baseline_samples], axis=1, keepdims=True)\n",
    "        data = data - baseline_mean \n",
    "\n",
    "        # Tính features\n",
    "        bp = compute_band_power(data, sfreq)\n",
    "        spec_ent = compute_spectral_entropy(data, sfreq)\n",
    "        wave_feats = compute_wavelet_features(data)\n",
    "        \n",
    "        # Truyền tên các kênh đã lọc vào để combine\n",
    "        feats = combine_features(bp, spec_ent, wave_feats, available_channels)\n",
    "\n",
    "        results.append([subject, preproc_file.name, idx, row[\"event_type\"]] + feats)\n",
    "\n",
    "    return results\n",
    "\n",
    "# =================== BATCH PROCESS ===================\n",
    "\n",
    "def extract_features_batch(derivatives_path, output_file='eeg_features_roi.csv', n_jobs=-1):\n",
    "    derivatives_path = Path(derivatives_path)\n",
    "    files = list(derivatives_path.rglob('*_desc-preproc_eeg.fif'))\n",
    "    print(f\"Tìm thấy {len(files)} file EEG\")\n",
    "\n",
    "    all_results = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(process_subject)(f) for f in files\n",
    "    )\n",
    "\n",
    "    flat = [item for sublist in all_results for item in sublist]\n",
    "\n",
    "    if not flat:\n",
    "        print(\"Không trích xuất được dữ liệu nào!\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df = pd.DataFrame(flat)\n",
    "    \n",
    "    # Tạo tên cột feature động dựa trên số lượng feature trích xuất được\n",
    "    n_meta_cols = 4 # subject, file, trial, label\n",
    "    n_feature_cols = df.shape[1] - n_meta_cols\n",
    "    feature_cols = [f\"feat_{i}\" for i in range(n_feature_cols)]\n",
    "    \n",
    "    df.columns = [\"subject\", \"file\", \"trial\", \"label\"] + feature_cols\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(\"DONE →\", output_file, \"shape:\", df.shape)\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    extract_features_batch(\n",
    "        \"data/EEG/derivatives/preprocessing\",\n",
    "        output_file=\"optimized_oddball_features.csv\",\n",
    "        n_jobs=-1\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731ac646",
   "metadata": {},
   "source": [
    "V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81aaa125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tìm thấy 42 file EEG\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:   36.6s\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=2)]: Done  14 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=2)]: Done  21 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=2)]: Done  42 out of  42 | elapsed: 12.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "✓ DONE → oddball_top3_features.csv\n",
      "  Shape: (29639, 8525)\n",
      "  Features:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ch_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 341\u001b[0m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;66;03m# =================== RUN ===================\u001b[39;00m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 341\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mextract_features_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/EEG/derivatives/preprocessing\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moddball_top3_features.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Giảm xuống 2 để tránh memory issues\u001b[39;49;00m\n\u001b[0;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 331\u001b[0m, in \u001b[0;36mextract_features_batch\u001b[1;34m(derivatives_path, output_file, n_jobs)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Features:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    - ERP: P300 peak/area/mean × \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(ch_names)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m channels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    - CSP: 4 components × 3 stats = 12 features\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    - Tangent space: Riemannian covariance features\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ch_names' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Code trích xuất 3 nhóm feature hiệu quả nhất cho Oddball paradigm:\n",
    "1. ERP peak/area (P300 components)\n",
    "2. CSP (Common Spatial Patterns) - thay thế xDAWN, nhẹ hơn\n",
    "3. Covariance → Tangent space features\n",
    "\n",
    "Memory-optimized version\n",
    "\"\"\"\n",
    "\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from scipy.integrate import simpson\n",
    "from pyriemann.estimation import Covariances\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "from joblib import Parallel, delayed\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# =================== CSP IMPLEMENTATION ===================\n",
    "\n",
    "def fit_csp(X, y, n_components=4):\n",
    "    \"\"\"\n",
    "    Common Spatial Pattern - memory efficient alternative to xDAWN\n",
    "    Args:\n",
    "        X: (n_trials, n_channels, n_times)\n",
    "        y: (n_trials,) binary labels (0 or 1)\n",
    "    Returns:\n",
    "        filters: (n_components, n_channels)\n",
    "    \"\"\"\n",
    "    n_channels = X.shape[1]\n",
    "    \n",
    "    # Separate by class\n",
    "    X_class0 = X[y == 0]\n",
    "    X_class1 = X[y == 1]\n",
    "    \n",
    "    if len(X_class0) == 0 or len(X_class1) == 0:\n",
    "        # Fallback: return identity-like filters\n",
    "        filters = np.eye(n_channels)[:n_components]\n",
    "        return filters\n",
    "    \n",
    "    # Compute average covariance for each class (memory efficient)\n",
    "    def avg_covariance(X_subset):\n",
    "        cov_sum = np.zeros((n_channels, n_channels))\n",
    "        n_samples = min(30, len(X_subset))  # Limit to 30 trials\n",
    "        for i in range(n_samples):\n",
    "            cov_sum += np.cov(X_subset[i])\n",
    "        return cov_sum / n_samples\n",
    "    \n",
    "    C0 = avg_covariance(X_class0)\n",
    "    C1 = avg_covariance(X_class1)\n",
    "    \n",
    "    # Composite covariance\n",
    "    C_composite = C0 + C1\n",
    "    \n",
    "    # Regularization\n",
    "    C_composite += 1e-6 * np.eye(n_channels)\n",
    "    \n",
    "    # Eigenvalue decomposition\n",
    "    try:\n",
    "        eigenvalues, eigenvectors = np.linalg.eigh(C0, C_composite)\n",
    "        # Sort by eigenvalues\n",
    "        idx = np.argsort(eigenvalues)[::-1]\n",
    "        # Take top and bottom components (most discriminative)\n",
    "        selected_idx = np.concatenate([idx[:n_components//2], idx[-n_components//2:]])\n",
    "        filters = eigenvectors[:, selected_idx].T\n",
    "    except:\n",
    "        # Fallback\n",
    "        U, s, Vt = np.linalg.svd(C0, full_matrices=False)\n",
    "        filters = U[:, :n_components].T\n",
    "    \n",
    "    return filters\n",
    "\n",
    "def compute_csp_features(X, y, n_components=4):\n",
    "    \"\"\"\n",
    "    Apply CSP filters and extract features\n",
    "    Args:\n",
    "        X: (n_trials, n_channels, n_times)\n",
    "        y: (n_trials,) binary labels\n",
    "    \"\"\"\n",
    "    filters = fit_csp(X, y, n_components)\n",
    "    \n",
    "    # Transform data\n",
    "    X_csp = np.zeros((X.shape[0], n_components, X.shape[2]))\n",
    "    for trial in range(X.shape[0]):\n",
    "        X_csp[trial] = filters @ X[trial]\n",
    "    \n",
    "    # Extract features per component\n",
    "    features = {}\n",
    "    for comp in range(n_components):\n",
    "        comp_data = X_csp[:, comp, :]\n",
    "        features[f'csp_c{comp}_var'] = np.var(comp_data, axis=1)\n",
    "        features[f'csp_c{comp}_mean'] = np.mean(comp_data, axis=1)\n",
    "        features[f'csp_c{comp}_max'] = np.max(comp_data, axis=1)\n",
    "    \n",
    "    return features\n",
    "\n",
    "# =================== ERP FEATURES ===================\n",
    "\n",
    "def compute_erp_features(data, sfreq, p300_window=(0.25, 0.5)):\n",
    "    \"\"\"\n",
    "    Tính P300 peak amplitude và area\n",
    "    \"\"\"\n",
    "    start_idx = int(p300_window[0] * sfreq)\n",
    "    end_idx = int(p300_window[1] * sfreq)\n",
    "    \n",
    "    # Handle edge cases\n",
    "    if end_idx > data.shape[1]:\n",
    "        end_idx = data.shape[1]\n",
    "    if start_idx >= end_idx:\n",
    "        start_idx = 0\n",
    "    \n",
    "    p300_segment = data[:, start_idx:end_idx]\n",
    "    \n",
    "    features = {}\n",
    "    features['p300_peak'] = np.max(p300_segment, axis=1)\n",
    "    features['p300_area'] = simpson(p300_segment, axis=1)\n",
    "    features['p300_mean'] = np.mean(p300_segment, axis=1)\n",
    "    \n",
    "    return features\n",
    "\n",
    "def extract_trial_features(data, sfreq, ch_names):\n",
    "    \"\"\"Extract ERP features for 1 trial\"\"\"\n",
    "    features = []\n",
    "    \n",
    "    erp_feats = compute_erp_features(data, sfreq)\n",
    "    for feat_name, feat_vals in erp_feats.items():\n",
    "        features.extend(feat_vals)\n",
    "    \n",
    "    return features\n",
    "\n",
    "# =================== TANGENT SPACE FEATURES ===================\n",
    "\n",
    "def compute_tangent_features(epochs_data, max_trials=100):\n",
    "    \"\"\"\n",
    "    Riemannian tangent space features - memory limited\n",
    "    \"\"\"\n",
    "    # Limit number of trials to prevent memory issues\n",
    "    if epochs_data.shape[0] > max_trials:\n",
    "        indices = np.random.choice(epochs_data.shape[0], max_trials, replace=False)\n",
    "        indices.sort()\n",
    "        epochs_subset = epochs_data[indices]\n",
    "    else:\n",
    "        epochs_subset = epochs_data\n",
    "        indices = np.arange(epochs_data.shape[0])\n",
    "    \n",
    "    try:\n",
    "        # Estimate covariance matrices\n",
    "        cov = Covariances(estimator='oas')  # OAS is faster than lwf\n",
    "        cov_matrices = cov.fit_transform(epochs_subset)\n",
    "        \n",
    "        # Project to tangent space\n",
    "        ts = TangentSpace(metric='riemann')\n",
    "        tangent_feats = ts.fit_transform(cov_matrices)\n",
    "        \n",
    "        # Expand back to full size if we sampled\n",
    "        if len(indices) < epochs_data.shape[0]:\n",
    "            full_tangent = np.zeros((epochs_data.shape[0], tangent_feats.shape[1]))\n",
    "            full_tangent[indices] = tangent_feats\n",
    "            # Fill missing with mean\n",
    "            mean_feat = np.mean(tangent_feats, axis=0)\n",
    "            mask = np.ones(epochs_data.shape[0], dtype=bool)\n",
    "            mask[indices] = False\n",
    "            full_tangent[mask] = mean_feat\n",
    "            return full_tangent\n",
    "        \n",
    "        return tangent_feats\n",
    "    except:\n",
    "        # Fallback: return zeros\n",
    "        return np.zeros((epochs_data.shape[0], 10))\n",
    "\n",
    "# =================== GROUP FEATURES ===================\n",
    "\n",
    "def extract_group_features(epochs_data, labels):\n",
    "    \"\"\"\n",
    "    Extract CSP and tangent features\n",
    "    \"\"\"\n",
    "    n_trials = epochs_data.shape[0]\n",
    "    \n",
    "    # Convert labels to binary\n",
    "    unique_labels = np.unique(labels)\n",
    "    y = np.array([0 if label == unique_labels[0] else 1 for label in labels])\n",
    "    \n",
    "    # CSP features\n",
    "    csp_feats = compute_csp_features(epochs_data, y, n_components=4)\n",
    "    \n",
    "    # Tangent space features (with memory limit)\n",
    "    tangent_feats = compute_tangent_features(epochs_data, max_trials=100)\n",
    "    \n",
    "    # Organize by trial\n",
    "    trial_features = {}\n",
    "    for trial_idx in range(n_trials):\n",
    "        feats = []\n",
    "        \n",
    "        # CSP features\n",
    "        for key in sorted(csp_feats.keys()):\n",
    "            feats.append(csp_feats[key][trial_idx])\n",
    "        \n",
    "        # Tangent features\n",
    "        feats.extend(tangent_feats[trial_idx])\n",
    "        \n",
    "        trial_features[trial_idx] = feats\n",
    "    \n",
    "    return trial_features\n",
    "\n",
    "# =================== PROCESS SUBJECT ===================\n",
    "\n",
    "def process_subject(preproc_file):\n",
    "    \"\"\"Process one subject\"\"\"\n",
    "    subject = preproc_file.parent.parent.name\n",
    "    \n",
    "    # Find events file\n",
    "    events_file = Path(f\"data/EEG/eeg/tsv/{subject}_task-oddball_events.tsv\")\n",
    "    \n",
    "    if not events_file.exists():\n",
    "        print(f\"⚠ Không tìm thấy events cho {subject}\")\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        # Load data\n",
    "        events_tsv = pd.read_csv(events_file, sep=\"\\t\")\n",
    "        raw = mne.io.read_raw_fif(preproc_file, preload=True, verbose=False)\n",
    "        sfreq = raw.info['sfreq']\n",
    "        ch_names = raw.ch_names\n",
    "        \n",
    "        # Create events array\n",
    "        events_array = []\n",
    "        event_mapping = {}\n",
    "        next_id = 1\n",
    "        \n",
    "        for idx, row in events_tsv.iterrows():\n",
    "            onset_sample = int(row[\"onset\"])\n",
    "            event_type = row[\"event_type\"]\n",
    "            \n",
    "            if event_type not in event_mapping:\n",
    "                event_mapping[event_type] = next_id\n",
    "                next_id += 1\n",
    "            \n",
    "            events_array.append([onset_sample, 0, event_mapping[event_type]])\n",
    "        \n",
    "        events_array = np.array(events_array)\n",
    "        \n",
    "        if len(events_array) == 0:\n",
    "            return []\n",
    "        \n",
    "        event_id_dict = {k: v for k, v in event_mapping.items()}\n",
    "        \n",
    "        # Create epochs\n",
    "        epochs = mne.Epochs(raw, events_array, event_id=event_id_dict,\n",
    "                            tmin=-0.2, tmax=0.8, baseline=(-0.2, 0),\n",
    "                            preload=True, verbose=False, \n",
    "                            reject_by_annotation=False)\n",
    "        \n",
    "        epochs_data = epochs.get_data()\n",
    "        labels = [events_tsv.iloc[i][\"event_type\"] for i in range(len(events_tsv))]\n",
    "        \n",
    "        # Check length match\n",
    "        if len(epochs_data) != len(labels):\n",
    "            min_len = min(len(epochs_data), len(labels))\n",
    "            epochs_data = epochs_data[:min_len]\n",
    "            labels = labels[:min_len]\n",
    "        \n",
    "        # Extract group features\n",
    "        group_features = extract_group_features(epochs_data, labels)\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        # Process each trial\n",
    "        for idx, row in events_tsv.iterrows():\n",
    "            if idx >= len(group_features):\n",
    "                continue\n",
    "            \n",
    "            onset_sample = int(row[\"onset\"])\n",
    "            label = row[\"event_type\"]\n",
    "            \n",
    "            segment_samples = int(1.0 * sfreq)\n",
    "            \n",
    "            if onset_sample + segment_samples > raw.n_times:\n",
    "                continue\n",
    "            \n",
    "            data = raw.get_data(start=onset_sample, stop=onset_sample + segment_samples)\n",
    "            \n",
    "            # ERP features\n",
    "            erp_feats = extract_trial_features(data, sfreq, ch_names)\n",
    "            \n",
    "            # Combine all features\n",
    "            all_feats = erp_feats + group_features[idx]\n",
    "            \n",
    "            results.append([subject, preproc_file.name, idx, label] + all_feats)\n",
    "        \n",
    "        print(f\"✓ {subject}: {len(results)} trials\")\n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error processing {subject}: {e}\")\n",
    "        return []\n",
    "\n",
    "# =================== BATCH PROCESS ===================\n",
    "\n",
    "def extract_features_batch(derivatives_path, output_file='oddball_top3_features.csv', n_jobs=2):\n",
    "    \"\"\"Process all subjects\"\"\"\n",
    "    derivatives_path = Path(derivatives_path)\n",
    "    files = list(derivatives_path.rglob('*_desc-preproc_eeg.fif'))\n",
    "    print(f\"Tìm thấy {len(files)} file EEG\\n\")\n",
    "    \n",
    "    # Process in parallel\n",
    "    all_results = Parallel(n_jobs=n_jobs, verbose=10)(\n",
    "        delayed(process_subject)(f) for f in files\n",
    "    )\n",
    "    \n",
    "    # Flatten\n",
    "    flat = [item for sublist in all_results for item in sublist]\n",
    "    \n",
    "    if len(flat) == 0:\n",
    "        print(\"⚠ Không có data nào được xử lý!\")\n",
    "        return None\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(flat)\n",
    "    df = df.rename(columns={0: \"subject\", 1: \"file\", 2: \"trial\", 3: \"label\"})\n",
    "    feature_cols = [f\"f{i}\" for i in range(df.shape[1] - 4)]\n",
    "    df.columns = [\"subject\", \"file\", \"trial\", \"label\"] + feature_cols\n",
    "    \n",
    "    df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"✓ DONE → {output_file}\")\n",
    "    print(f\"  Shape: {df.shape}\")\n",
    "    print(f\"  Features:\")\n",
    "    print(f\"    - ERP: P300 peak/area/mean × {len(ch_names)} channels\")\n",
    "    print(f\"    - CSP: 4 components × 3 stats = 12 features\")\n",
    "    print(f\"    - Tangent space: Riemannian covariance features\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# =================== RUN ===================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = extract_features_batch(\n",
    "        \"data/EEG/derivatives/preprocessing\",\n",
    "        output_file=\"oddball_top3_features.csv\",\n",
    "        n_jobs=2  # Giảm xuống 2 để tránh memory issues\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e72b0988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy version: 1.26.4\n",
      "MNE version: 1.10.2\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import scipy\n",
    "import mne\n",
    "\n",
    "print(f\"Numpy version: {numpy.__version__}\")\n",
    "print(f\"MNE version: {mne.__version__}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
